{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff2a5c2-d0d0-4c54-a0ff-afd71ebb1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a7dc6d-37db-4ef6-b914-b4dbae10c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torchtext -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b68dfe-4424-4a08-b506-d52fea9dea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext==0.17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989d7384-cf6c-4f8a-8fb1-efe3132a2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import *\n",
    "import nltk\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9423e9b-3f75-49e0-9e77-8898436a2fd9",
   "metadata": {},
   "source": [
    "![example of positional encoding](./images/img_positional_encoding.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2b5b11-0ea6-4d5f-b9b9-57acd07f7af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/developer/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c645d4d-b494-4690-98c4-efee904efcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"I wonder what will come next\",\n",
    "             \"This is a basic example paragraph\",\n",
    "             \"Hello, what is a basic split?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7011d48f-bf37-4676-a56c-5eb9137e1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sequences = []\n",
    "# 구두점 정의\n",
    "punctuations = [',', '?', '!', '.']\n",
    "for seq in sequences:\n",
    "    tokens = word_tokenize(seq)\n",
    "    filtered_tokens = [token for token in tokens if token not in punctuations]\n",
    "    tokenized_sequences.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8ad5e0-0a91-468f-86bb-c39d39d62b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'wonder', 'what', 'will', 'come', 'next'],\n",
       " ['This', 'is', 'a', 'basic', 'example', 'paragraph'],\n",
       " ['Hello', 'what', 'is', 'a', 'basic', 'split']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20d1542-0296-44b8-9b6f-bf79d5a05aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: a, Index: 0\n",
      "Token: This, Index: 6\n",
      "Token: wonder, Index: 13\n",
      "Token: next, Index: 9\n",
      "Token: basic, Index: 1\n",
      "Token: is, Index: 2\n",
      "Token: what, Index: 3\n",
      "Token: Hello, Index: 4\n",
      "Token: paragraph, Index: 10\n",
      "Token: I, Index: 5\n",
      "Token: example, Index: 8\n",
      "Token: split, Index: 11\n",
      "Token: come, Index: 7\n",
      "Token: will, Index: 12\n"
     ]
    }
   ],
   "source": [
    "# set the output to 2 decimal places without scientific notation\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "vocab = build_vocab_from_iterator(tokenized_sequences)\n",
    "stoi = vocab.get_stoi()\n",
    "for token, index in stoi.items():\n",
    "    print(f\"Token: {token}, Index: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0896f5-008a-40f0-a871-89be34be2d26",
   "metadata": {},
   "source": [
    "vocab.get_stoi()는 {\"단어\": 인덱스} 형태의 dict 임. \n",
    "\n",
    "``` python\n",
    "stoi = vocab.get_stoi()\n",
    "for token, index in stoi.items():\n",
    "    print(f\"Token: {token}, Index: {index}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda7c6ce-54f9-4fec-9c32-23d08c2ef5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = vocab.get_stoi()\n",
    "# index the sequences \n",
    "indexed_sequences = [[stoi[word] for word in seq] for seq in tokenized_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d958f1-9bd0-47bd-876f-402ab5a2fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 13, 3, 12, 7, 9], [6, 2, 0, 1, 8, 10], [4, 3, 2, 0, 1, 11]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a94a0466-4cdb-42d0-8ee0-6c0b69a6a22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "172a33a1-83cb-4737-b458-a8f7a263893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[     0.53,     -0.97,     -2.19,      0.71],\n",
       "         [     0.52,      0.85,     -0.07,     -0.54],\n",
       "         [    -1.08,      0.13,     -0.13,      0.97],\n",
       "         [     0.40,      0.64,      0.17,     -0.86],\n",
       "         [    -0.99,      0.66,      0.55,     -1.31],\n",
       "         [     0.60,      0.55,     -0.57,      0.44]],\n",
       "\n",
       "        [[    -0.37,      0.42,     -0.30,     -0.33],\n",
       "         [    -0.07,     -0.86,      0.32,     -0.19],\n",
       "         [    -1.62,     -1.25,      1.27,      0.24],\n",
       "         [     1.33,      1.08,      0.00,     -0.50],\n",
       "         [    -1.11,     -1.39,      1.09,     -0.17],\n",
       "         [     0.35,      0.57,      1.54,      0.88]],\n",
       "\n",
       "        [[     0.28,     -1.27,      0.10,      0.73],\n",
       "         [    -1.08,      0.13,     -0.13,      0.97],\n",
       "         [    -0.07,     -0.86,      0.32,     -0.19],\n",
       "         [    -1.62,     -1.25,      1.27,      0.24],\n",
       "         [     1.33,      1.08,      0.00,     -0.50],\n",
       "         [    -0.72,      1.23,     -1.48,     -0.09]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the sequences to a tensor\n",
    "tensor_sequences = torch.tensor(indexed_sequences).long()\n",
    "\n",
    "# vocab size\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "# embedding dimensions\n",
    "d_model = 4\n",
    "\n",
    "# create the embeddings\n",
    "lut = nn.Embedding(vocab_size, d_model) # look-up table (lut)\n",
    "\n",
    "# embed the sequence\n",
    "embeddings = lut(tensor_sequences)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b322ba4b-6688-4e20-91ac-3a457b4ca988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e97439b-45ee-4e55-b445-a01782b9a86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e64eb4-0ff1-4b61-9382-a04830ce081f",
   "metadata": {},
   "source": [
    "다음 단계는 각 시퀀스 내 각 단어의 위치를 위치 인코딩(positional encoding)을 통해 인코딩하는 것입니다.  \n",
    "아래 함수는 위 정의를 따릅니다. 언급할 만한 유일한 변화는 **𝐿** 이 **_max_length_** 로 표기된다는 점입니다.  \n",
    "이는 거의 모든 시퀀스를 적절히 인코딩할 수 있도록 보장하기 위해 보통 수천 단위의 매우 큰 값으로  \n",
    "설정됩니다.   \n",
    "이를 통해 동일한 위치 인코딩 행렬을 다양한 길이의 시퀀스에 사용할 수 있으며, 추가 전에 적절한 길이로  \n",
    "잘라낼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976c576-62da-45fd-a4c0-5a122f75f612",
   "metadata": {},
   "source": [
    "![positional formula](./images/pe_formula.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2444c6-9ac8-4d83-82c6-7a6f01bdf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pe(max_length, d_model, n):\n",
    "\n",
    "  # generate an empty matrix for the positional encodings (pe)\n",
    "  pe = np.zeros(max_length*d_model).reshape(max_length, d_model) \n",
    "\n",
    "  # for each position\n",
    "  for k in np.arange(max_length):\n",
    "\n",
    "    # for each dimension\n",
    "    for i in np.arange(d_model//2):\n",
    "\n",
    "      # calculate the internal value for sin and cos\n",
    "      theta = k / (n ** ((2*i)/d_model))       \n",
    "\n",
    "      # even dims: sin   \n",
    "      pe[k, 2*i] = math.sin(theta) \n",
    "\n",
    "      # odd dims: cos               \n",
    "      pe[k, 2*i+1] = math.cos(theta)\n",
    "\n",
    "  return pe\n",
    "\n",
    "# maximum sequence length\n",
    "max_length = 10\n",
    "n = 1000\n",
    "encodings = gen_pe(max_length, d_model, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d66a9e-cf8f-4d6e-87ed-173fa8e728cf",
   "metadata": {},
   "source": [
    "The output of the encoding contains 10 position encoding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c93517a-1869-492f-b05b-3f3c4cd47ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
       "       [ 0.84147098,  0.54030231,  0.03161751,  0.99950004],\n",
       "       [ 0.90929743, -0.41614684,  0.0632034 ,  0.99800067],\n",
       "       [ 0.14112001, -0.9899925 ,  0.09472609,  0.99550337],\n",
       "       [-0.7568025 , -0.65364362,  0.12615407,  0.99201066],\n",
       "       [-0.95892427,  0.28366219,  0.1574559 ,  0.98752602],\n",
       "       [-0.2794155 ,  0.96017029,  0.18860029,  0.98205394],\n",
       "       [ 0.6569866 ,  0.75390225,  0.21955609,  0.97559988],\n",
       "       [ 0.98935825, -0.14550003,  0.25029236,  0.9681703 ],\n",
       "       [ 0.41211849, -0.91113026,  0.28077835,  0.95977264]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe6201-b391-4ed3-b864-1208b82159f3",
   "metadata": {},
   "source": [
    "앞서 언급했듯이, **_max_length_** 는 10으로 설정됩니다.  \n",
    "이는 필요한 길이보다 크지만, 길이가 7, 8, 9 또는 10인 다른 시퀀스가  \n",
    "있을 경우 동일한 위치 인코딩 행렬을 사용할 수 있도록 보장하기 위함입니다.   \n",
    "단지 적절한 길이로 잘라내면 됩니다.  \n",
    "아래에서는 임베딩의 시퀀스 길이가 6이므로 인코딩을 이에 맞게 잘라낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cdd2440-04a3-4735-a105-1661854e6337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
       "       [ 0.84147098,  0.54030231,  0.03161751,  0.99950004],\n",
       "       [ 0.90929743, -0.41614684,  0.0632034 ,  0.99800067],\n",
       "       [ 0.14112001, -0.9899925 ,  0.09472609,  0.99550337],\n",
       "       [-0.7568025 , -0.65364362,  0.12615407,  0.99201066],\n",
       "       [-0.95892427,  0.28366219,  0.1574559 ,  0.98752602]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the first six tokens\n",
    "seq_length = embeddings.shape[1]\n",
    "encodings[:seq_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e395c10-b314-4bd1-827a-054bbe7e48e4",
   "metadata": {},
   "source": [
    "모든 시퀀스의 길이가 동일하므로 하나의 위치 인코딩 행렬만 필요하며,  \n",
    "이를 PyTorch를 사용하여 세 시퀀스에 모두 브로드캐스트할 수 있습니다.   \n",
    "이 예제에서 임베딩된 배치의 형태는 (3,6,4)이고, 위치 인코딩은 잘라내기  \n",
    "전에는 (10,4) 형태를 가지며, 잘라낸 후에는 (6,4) 형태가 됩니다.  \n",
    "이 행렬은 이후 (3,6,4) 인코딩 행렬을 생성하기 위해 브로드캐스트됩니다  \n",
    "(이미지에서 확인 가능).   \n",
    "\n",
    "브로드캐스트에 대한 자세한 내용은 A Simple Introduction to Broadcasting을 참조하세요.  \n",
    "이 과정 덕분에 두 행렬을 문제없이 더할 수 있습니다.  \n",
    "\n",
    "When the positional encodings are added to the embeddings,  \n",
    "the output is the same as the image at the beginning of the section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aac07a0-0f5e-48f3-85e3-43eeaf929fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.90,  0.29,  1.73,  0.89],\n",
       "         [ 1.65, -0.96,  1.77,  1.36],\n",
       "         [ 0.92, -0.20, -1.15,  1.43],\n",
       "         [ 0.11, -0.73, -0.24,  0.53],\n",
       "         [-1.85,  0.07,  1.75,  0.91],\n",
       "         [-1.98, -1.33, -1.04,  0.40]],\n",
       "\n",
       "        [[ 0.13,  0.79,  0.03,  1.79],\n",
       "         [-0.03,  0.41,  0.03,  2.61],\n",
       "         [ 1.54, -0.98,  0.38,  1.74],\n",
       "         [ 0.77, -1.34, -0.80,  0.90],\n",
       "         [-0.59, -1.53, -0.90,  1.71],\n",
       "         [-0.79, -0.43, -0.77,  0.39]],\n",
       "\n",
       "        [[ 0.37,  1.16, -1.41,  2.23],\n",
       "         [ 0.85,  0.76, -1.18,  1.43],\n",
       "         [ 0.03, -0.55,  0.07,  2.61],\n",
       "         [ 0.77, -1.55,  0.41,  1.74],\n",
       "         [-0.13, -1.01, -0.77,  0.90],\n",
       "         [-0.85,  0.06, -0.18,  0.27]]], dtype=torch.float64,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings + torch.tensor(encodings[:seq_length]) # encodings[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a948362-6aa5-403c-ba50-3bd892a2a88c",
   "metadata": {},
   "source": [
    "이 출력은 모델의 다음 계층인 **멀티헤드 어텐션(Multi-head Attention)**으로 전달됩니다.   \n",
    "멀티헤드 어텐션은 다음 기사에서 다룰 예정입니다.  \n",
    "\n",
    "하지만 이 기본 구현은 중첩 루프(nested loop)를 사용하기 때문에, 특히 $d_{model}$ 과   \n",
    "**_max_length_** 값이 클 경우 비효율적입니다.   \n",
    "대신, PyTorch 중심의 더 효율적인 접근 방식을 사용할 수 있습니다.\n",
    "\n",
    "![](./images/formula_2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c340ab4-52be-4df0-95c2-dd5a8e0366aa",
   "metadata": {},
   "source": [
    "PyTorch의 기능을 활용하기 위해, 원래의 수식,   \n",
    "특히 분모 부분을 로그 규칙을 사용하여 수정해야 합니다.\n",
    "\n",
    "분모는 다음과 같습니다:\n",
    "\n",
    "$\\Large \\frac{1}{n^\\frac{2i}{d_model}}$\n",
    "\n",
    "분모를 수정하기 위해 𝑛의 지수를 음수로 만들어 분자로 이동시킵니다.    \n",
    "그런 다음, 규칙 7을 사용하여 전체 수식을 𝑒의 지수로 변환합니다. 이후,   \n",
    "규칙 3을 사용하여 지수를 로그(log) 바깥으로 꺼냅니다.   \n",
    "이를 간소화하면 최종 결과를 얻을 수 있습니다.\n",
    "\n",
    "$\\Large \\frac{1}{n^\\frac{2i}{d_model}} = n^{-\\frac{2i}{d_{model}}} = e^{log{(n^{-\\frac{2i}{d_{model}}})}} = e^{-\\frac{2i\\ log(n)}{d_{model}}} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09fb52-4367-4dc6-b27b-bef86b09bbe3",
   "metadata": {},
   "source": [
    "이는 위치 인코딩의 모든 분모를 한 번에 생성하는 데 사용할 수 있기 때문에 중요합니다.  \n",
    "아래에서 알 수 있듯이, 4차원 임베딩의 경우 필요한 분모는 두 개뿐입니다.  \n",
    "이는 𝑖가 차원을 나타낼 때, 분모가 2i마다 한 번씩만 변하기 때문입니다.   \n",
    "이러한 패턴은 각 위치에서 반복됩니다:  \n",
    "\n",
    "![](./images/pe_formula_3.webp)\n",
    "\n",
    "Since only the highest number that i can be set to is d_model divided by 2,   \n",
    "the terms can be calculated once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51102613-5707-481d-8b20-c167f401d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 4\n",
    "n = 100\n",
    "\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(n) / d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac8d75-95a1-43d3-bceb-905594c3e5c3",
   "metadata": {},
   "source": [
    "이 짧은 코드 조각은 필요한 모든 분모를 생성하는 데 사용할 수 있습니다.  \n",
    "이 예제에서는 d_{model}이 4로 설정되었고, n은 100으로 설정되었습니다.  \n",
    "출력 결과는 두 개의 분모입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a009a7-7e3a-4e7c-885a-3e428566ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.00, 0.10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aff532-9c8f-4450-b2ac-692ac3336e82",
   "metadata": {},
   "source": [
    "여기서부터는 PyTorch의 인덱싱 기능을 활용하여 몇 줄의 코드로 \n",
    "전체 위치 인코딩 행렬을 생성할 수 있습니다. 다음 단계는 \n",
    "𝑘 부터 L−1까지 각 위치를 생성하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2175035-7a08-420c-9e73-5f9b03595cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "max_length = 10\n",
    "\n",
    "# generate the positions into a column matrix\n",
    "k = torch.arange(0, max_length).unsqueeze(1) \n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082f96b-7b8d-45dd-87d2-fdda96c8cbcb",
   "metadata": {},
   "source": [
    "위치와 분모가 준비되었으므로, 사인(sin) 및 코사인(cos) 함수의 내부 값을  \n",
    "쉽게 계산할 수 있습니다.\n",
    "\n",
    "![](./images/pe_formula_4.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd88fc3-2d3c-4444-8a0c-16caf804bf58",
   "metadata": {},
   "source": [
    "k와 div_term을 곱하면 모든 위치에 대한 입력값을 계산할 수 있습니다.   \n",
    "PyTorch는 행렬을 자동으로 브로드캐스트하여 곱셈을 수행합니다.   \n",
    "이 경우, 대응하는 요소끼리 곱해지는 **아다마르 곱(Hadamard product)** 이며,  \n",
    "행렬 곱셈이 아님을 유의하세요:\n",
    "\n",
    "![](./images/pe_formula_5.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2732d36-8691-48ce-9aa0-fccf88dda7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.00, 0.00],\n",
       "        [1.00, 0.10],\n",
       "        [2.00, 0.20],\n",
       "        [3.00, 0.30],\n",
       "        [4.00, 0.40],\n",
       "        [5.00, 0.50],\n",
       "        [6.00, 0.60],\n",
       "        [7.00, 0.70],\n",
       "        [8.00, 0.80],\n",
       "        [9.00, 0.90]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k*div_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737c809-7633-4530-9668-c443d8b47111",
   "metadata": {},
   "source": [
    "이 계산의 출력 결과는 위 이미지에서 확인할 수 있습니다.   \n",
    "이제 남은 작업은 입력값을 사인(sin)과 코사인(cos) 함수에 넣고,   \n",
    "이를 적절히 행렬에 저장하는 것입니다.  \n",
    "\n",
    "이를 시작하려면 적절한 크기의 빈 행렬을 생성하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c95cfa7-eecf-4faa-ac66-584935e8024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# generate an empty tensor\n",
    "pe = torch.zeros(max_length, d_model)\n",
    "\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd4507-a0de-4d04-a403-52582c2af5a3",
   "metadata": {},
   "source": [
    "이제 짝수 열(사인 값을 나타냄)은 pe[:, 0::2]를 사용하여 선택할 수 있습니다.  \n",
    "이는 PyTorch에게 모든 행과 짝수 열을 선택하라는 의미입니다.   \n",
    "동일하게 홀수 열(코사인 값을 나타냄)은 pe[:, 1::2]를 사용하여 선택할 수 있습니다.   \n",
    "이는 PyTorch에게 모든 행과 홀수 열을 선택하라는 의미입니다.  \n",
    "k×div_term의 결과는 필요한 모든 입력값을 저장하고 있으므로,   \n",
    "이를 사용하여 각 짝수 및 홀수 열을 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e23e1102-46af-41b0-8fba-a596a81fb50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.00,  1.00,  0.00,  1.00],\n",
      "         [ 0.84,  0.54,  0.10,  1.00],\n",
      "         [ 0.91, -0.42,  0.20,  0.98],\n",
      "         [ 0.14, -0.99,  0.30,  0.96],\n",
      "         [-0.76, -0.65,  0.39,  0.92],\n",
      "         [-0.96,  0.28,  0.48,  0.88],\n",
      "         [-0.28,  0.96,  0.56,  0.83],\n",
      "         [ 0.66,  0.75,  0.64,  0.76],\n",
      "         [ 0.99, -0.15,  0.72,  0.70],\n",
      "         [ 0.41, -0.91,  0.78,  0.62]]])\n"
     ]
    }
   ],
   "source": [
    "# set the odd values (columns 1 and 3)\n",
    "pe[:, 0::2] = torch.sin(k * div_term)\n",
    "\n",
    "# set the even values (columns 2 and 4)\n",
    "pe[:, 1::2] = torch.cos(k * div_term)\n",
    "     \n",
    "# add a dimension for broadcasting across sequences: optional       \n",
    "pe = pe.unsqueeze(0)\n",
    "\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79215dc-a422-4678-a4df-44fe003b41f3",
   "metadata": {},
   "source": [
    "이 값들은 중첩 for-루프를 사용하여 얻은 값과 동일합니다.   \n",
    "요약하자면, 아래는 모든 코드를 하나로 정리한 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eeb2adc-f61d-4cf7-b70a-2b6d1c4eb89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.00,  1.00,  0.00,  1.00],\n",
       "         [ 0.84,  0.54,  0.10,  1.00],\n",
       "         [ 0.91, -0.42,  0.20,  0.98],\n",
       "         [ 0.14, -0.99,  0.30,  0.96],\n",
       "         [-0.76, -0.65,  0.39,  0.92],\n",
       "         [-0.96,  0.28,  0.48,  0.88],\n",
       "         [-0.28,  0.96,  0.56,  0.83],\n",
       "         [ 0.66,  0.75,  0.64,  0.76],\n",
       "         [ 0.99, -0.15,  0.72,  0.70],\n",
       "         [ 0.41, -0.91,  0.78,  0.62]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 10\n",
    "d_model = 4\n",
    "n = 100\n",
    "\n",
    "def gen_pe(max_length, d_model, n):\n",
    "  # calculate the div_term\n",
    "  div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(n) / d_model))\n",
    "\n",
    "  # generate the positions into a column matrix\n",
    "  k = torch.arange(0, max_length).unsqueeze(1)\n",
    "\n",
    "  # generate an empty tensor\n",
    "  pe = torch.zeros(max_length, d_model)\n",
    "\n",
    "  # set the even values\n",
    "  pe[:, 0::2] = torch.sin(k * div_term)\n",
    "\n",
    "  # set the odd values\n",
    "  pe[:, 1::2] = torch.cos(k * div_term)\n",
    "\n",
    "  # add a dimension       \n",
    "  pe = pe.unsqueeze(0)        \n",
    "\n",
    "  # the output has a shape of (1, max_length, d_model)\n",
    "  return pe                           \n",
    "\n",
    "gen_pe(max_length, d_model, n)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5df7e-c332-47e3-bdab-d4e16fa404d2",
   "metadata": {},
   "source": [
    "더 복잡하긴 하지만, PyTorch는 향상된 성능을 제공하기 때문에   \n",
    "이 구현 방식을 머신 러닝에 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7e1c5-5e9d-48cd-9f11-56fcbd10955f",
   "metadata": {},
   "source": [
    "**Positional Encoding in Transformers**\n",
    "\n",
    "이제 복잡한 작업이 끝났으므로 구현은 비교적 간단합니다.   \n",
    "이 구현은 The Annotated Transformer와 PyTorch에서 파생되었습니다.  \n",
    "참고로 n의 기본값은 10,000이며, max_length의 기본값은 5,000입니다.  \n",
    "\n",
    "이 구현은 또한 **드롭아웃(dropout)** 을 포함합니다.   \n",
    "드롭아웃은 주어진 확률p에 따라 입력 요소 일부를 랜덤하게 0으로 설정합니다.     \n",
    "이는 정규화(regularization)에 도움을 주며, 뉴런들이 서로 과도하게   \n",
    "의존(co-adapting)하는 것을 방지합니다.  \n",
    "출력값은 또한 $\\frac{1}{1-p}$로 스케일링됩니다.  \n",
    "이 기사에서 드롭아웃에 대해 깊이 다루지는 않으니, 자세한 내용은   \n",
    "**드롭아웃 레이어(Dropout Layer)** 에 관한 기사를 참조하세요.  \n",
    "\n",
    "트랜스포머 모델의 나머지 부분으로 넘어가기 전에 드롭아웃에   \n",
    "익숙해지는 것이 중요합니다.   \n",
    "드롭아웃은 거의 모든 다른 계층에서도 사용되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88e3863e-8c50-4476-9565-135de343f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, d_model: int, dropout: float = 0.1, max_length: int = 5000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      d_model:      dimension of embeddings\n",
    "      dropout:      randomly zeroes-out some of the input\n",
    "      max_length:   max sequence length\n",
    "    \"\"\"\n",
    "    # inherit from Module\n",
    "    super().__init__()     \n",
    "\n",
    "    # initialize dropout                  \n",
    "    self.dropout = nn.Dropout(p=dropout)      \n",
    "\n",
    "    # create tensor of 0s\n",
    "    pe = torch.zeros(max_length, d_model)    \n",
    "\n",
    "    # create position column   \n",
    "    k = torch.arange(0, max_length).unsqueeze(1)  \n",
    "\n",
    "    # calc divisor for positional encoding \n",
    "    div_term = torch.exp(                                 \n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "    )\n",
    "\n",
    "    # calc sine on even indices\n",
    "    pe[:, 0::2] = torch.sin(k * div_term)    \n",
    "\n",
    "    # calc cosine on odd indices   \n",
    "    pe[:, 1::2] = torch.cos(k * div_term)  \n",
    "\n",
    "    # add dimension     \n",
    "    pe = pe.unsqueeze(0)          \n",
    "\n",
    "    # buffers are saved in state_dict but not trained by the optimizer                        \n",
    "    self.register_buffer(\"pe\", pe)                        \n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x:        embeddings (batch_size, seq_length, d_model)\n",
    "    \n",
    "    Returns:\n",
    "                embeddings + positional encodings (batch_size, seq_length, d_model)\n",
    "    \"\"\"\n",
    "    # add positional encoding to the embeddings\n",
    "    x = x + self.pe[:, : x.size(1)].requires_grad_(False) \n",
    "\n",
    "    # perform dropout\n",
    "    return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6eb46-7e65-4fc2-bf18-2a9112efffcf",
   "metadata": {},
   "source": [
    "**Forward Pass**\n",
    "\n",
    "To perform the forward pass, the same embedded sequences from earlier can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a269f5ca-66c2-4110-9fb5-3884b7fde89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.90, -0.71,  1.73, -0.11],\n",
       "         [ 0.81, -1.50,  1.74,  0.36],\n",
       "         [ 0.01,  0.22, -1.21,  0.43],\n",
       "         [-0.03,  0.26, -0.34, -0.47],\n",
       "         [-1.09,  0.73,  1.63, -0.09],\n",
       "         [-1.02, -1.61, -1.20, -0.59]],\n",
       "\n",
       "        [[ 0.13, -0.21,  0.03,  0.79],\n",
       "         [-0.88, -0.13,  0.00,  1.61],\n",
       "         [ 0.63, -0.56,  0.31,  0.74],\n",
       "         [ 0.63, -0.35, -0.90, -0.10],\n",
       "         [ 0.17, -0.87, -1.02,  0.72],\n",
       "         [ 0.17, -0.72, -0.93, -0.60]],\n",
       "\n",
       "        [[ 0.37,  0.16, -1.41,  1.23],\n",
       "         [ 0.01,  0.22, -1.21,  0.43],\n",
       "         [-0.88, -0.13,  0.00,  1.61],\n",
       "         [ 0.63, -0.56,  0.31,  0.74],\n",
       "         [ 0.63, -0.35, -0.90, -0.10],\n",
       "         [ 0.11, -0.22, -0.33, -0.71]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417ba32-3dee-482f-a531-d297efd02656",
   "metadata": {},
   "source": [
    "시퀀스가 임베딩된 후, 위치 인코딩 행렬을 생성할 수 있습니다.   \n",
    "드롭아웃은 임베딩과 위치 인코딩 간의 합산을 쉽게 확인할 수 있도록 0.0으로 설정되었습니다.  \n",
    "값이 처음부터 구현한 값과 다른 이유는 n의 기본값이 100이 아닌 10,000으로 설정되었기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5456644e-9832-41c4-bba8-82cd8999d018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('pe',\n",
       "              tensor([[[ 0.00,  1.00,  0.00,  1.00],\n",
       "                       [ 0.84,  0.54,  0.01,  1.00],\n",
       "                       [ 0.91, -0.42,  0.02,  1.00],\n",
       "                       [ 0.14, -0.99,  0.03,  1.00],\n",
       "                       [-0.76, -0.65,  0.04,  1.00],\n",
       "                       [-0.96,  0.28,  0.05,  1.00],\n",
       "                       [-0.28,  0.96,  0.06,  1.00],\n",
       "                       [ 0.66,  0.75,  0.07,  1.00],\n",
       "                       [ 0.99, -0.15,  0.08,  1.00],\n",
       "                       [ 0.41, -0.91,  0.09,  1.00]]]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 4\n",
    "max_length = 10\n",
    "dropout = 0.0\n",
    "\n",
    "# create the positional encoding matrix\n",
    "pe = PositionalEncoding(d_model, dropout, max_length)\n",
    "\n",
    "# preview the values\n",
    "pe.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67f9b5-f320-4d5b-9b03-b7476f6abec3",
   "metadata": {},
   "source": [
    "합산하기 전에 시퀀스의 형태는 (batch_size,seq_length,d_model), 즉 (3,6,4)입니다.  \n",
    "위치 인코딩도 잘라내고 브로드캐스트된 후 동일한 크기를 가지므로,   \n",
    "순방향 전달(forward pass)의 출력 크기도 (batch_size,seq_length,d_model),    \n",
    "즉 (3,6,4)로 유지됩니다. 이는 4차원 공간에 임베딩된 6개의 토큰으로 이루어진   \n",
    "3개의 시퀀스를 나타내며, 위치 인코딩을 통해 각 토큰의 시퀀스 내 위치를 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abbc2d05-18bf-4139-9946-50fcade3f6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.90,  0.29,  1.73,  0.89],\n",
       "         [ 1.65, -0.96,  1.75,  1.36],\n",
       "         [ 0.92, -0.20, -1.19,  1.43],\n",
       "         [ 0.11, -0.73, -0.31,  0.53],\n",
       "         [-1.85,  0.07,  1.67,  0.91],\n",
       "         [-1.98, -1.33, -1.15,  0.41]],\n",
       "\n",
       "        [[ 0.13,  0.79,  0.03,  1.79],\n",
       "         [-0.03,  0.41,  0.01,  2.61],\n",
       "         [ 1.54, -0.98,  0.33,  1.74],\n",
       "         [ 0.77, -1.34, -0.87,  0.90],\n",
       "         [-0.59, -1.53, -0.98,  1.72],\n",
       "         [-0.79, -0.43, -0.88,  0.40]],\n",
       "\n",
       "        [[ 0.37,  1.16, -1.41,  2.23],\n",
       "         [ 0.85,  0.76, -1.20,  1.43],\n",
       "         [ 0.03, -0.55,  0.02,  2.61],\n",
       "         [ 0.77, -1.55,  0.34,  1.74],\n",
       "         [-0.13, -1.01, -0.86,  0.90],\n",
       "         [-0.85,  0.06, -0.28,  0.28]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8fcff-839b-4b39-87d2-31efc9e895f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
