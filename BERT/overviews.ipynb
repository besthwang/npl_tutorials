{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145fb0cf-106c-46ee-871a-e7ab51523ea0",
   "metadata": {},
   "source": [
    "### 참고문헌\n",
    "\n",
    "\\[1\\] [17-02 버트(Bidirectional Encoder Representations from Transformers, BERT)](https://wikidocs.net/115055)  \n",
    "\\[2\\] [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)  \n",
    "\\[3\\] [\\[BERT\\] 버트 소스코드 이해](https://hyen4110.tistory.com/87)  \n",
    "\\[4\\] [Transformers(신경망 언어모델 라이브러리) 강좌](https://wikidocs.net/book/8056)\n",
    "\\[5\\] [A Complete Guide to BERT with Code](https://towardsdatascience.com/a-complete-guide-to-bert-with-code-9f87602e4a11/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c21301-f798-4b6d-aacc-7ec5183d45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5145842-c087-48ae-a2b5-43289668312f",
   "metadata": {},
   "source": [
    "BERT는 기본적으로 훈련된 트랜스포머 인코더 스택임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd22fde-a9b1-4990-b138-56576c7defb4",
   "metadata": {},
   "source": [
    "기본적인 Bert 모델의 사용은 아래 코드와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d4126b-b4f0-4fa3-8c56-0ddc304942db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe1079-e461-4826-bb91-a6994ae3603e",
   "metadata": {},
   "source": [
    "## 1. BertTokenizer의 이해\n",
    "- Tokenizer 정의 : 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업\n",
    "- **BertTokenizer**는 무엇이 특별한가?  \n",
    "  - `WordPiece Tokenizer`(BPE의 변형 알고리즘) 적용  \n",
    "  - `BPE(Byte Pair Encoding)` : OOV(Out-Of-Vocabulary)문제를 완화하기위한 대표적인 서브워드 분리 일고리즘  \n",
    "  - 서브워드 분리(Subword segmentation): 하나의 단어는 더 작은 단위의 의미있는 여러 서브워드들(Ex)  \n",
    "     `birthplace = birth + place`의 조합으로 구성된 경우가 많기 때문에, 하나의 단어를 여러 서브워드로 분리  \n",
    "     해서 단어를 인코딩 및 임베딩하겠다는 의도를 가진 전처리 작업 \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a1802e-c40b-428f-8013-d3d6ac5ee4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1fb85-58a2-42f5-bd4c-6ea57bd0445c",
   "metadata": {},
   "source": [
    "``` python\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "```\n",
    "\n",
    "- 토크나이징(Tokenizing)\n",
    "입력된 문장을 WordPiece 방식으로 잘게 나붑니다.예)\n",
    "```\n",
    "tokenizer.tokenize(\"apple people water\")\n",
    "→ ['apple', 'people', 'water']\n",
    "```\n",
    "\n",
    "- 토큰을 숫자 ID로 변환(Convert tokens to IDs)\n",
    "``` \n",
    "  tokenizer.convert_tokens_to_ids(['apple', 'people', 'water'])\n",
    "→ [6207, 2111, 2300]   # 숫자는 vocab에 따라 다름\n",
    "```\n",
    "\n",
    "- [CLS]와 [SEP] 토큰 자동 추가\n",
    "BERT는 문장의 시작과 끝에 특별한 토큰을 붙입니다.:\n",
    "```\n",
    "[CLS] apple people water [SEP]\n",
    "```\n",
    "\n",
    "이걸 숫자 ID로 변환한 전체 결과는 다음과 같을 수 있음.\n",
    "```\n",
    "[101, 6207, 2111, 2300, 102]\n",
    "```\n",
    "    - `101`: [CLS]\n",
    "    - `102`: [SEP]\n",
    "\n",
    "- PyTorch 텐서로 변환\n",
    "return_tensors='pt' 옵션 덕분에 결과는 PyTorch 텐서로 변환됨. 예:\n",
    "``` python\n",
    "inputs = {\n",
    "    'input_ids': tensor([[101,6207, 2111, 2300, 102]]),\n",
    "    'attention_mask': tensor([[1,1,1,1]])\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb3af64-71c4-4117-8a92-0f3a6e2f1b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc8c94-b067-48f7-816e-4b6b4bea5bf5",
   "metadata": {},
   "source": [
    "### BertTokenizer의 output 해부\n",
    "input_ids  \n",
    ":  (torch.LongTensor of shape ({0})  \n",
    ": Indices of input sequence tokens in the vocabulary.  \n",
    ": Indices can be obtained using [BertTokenizer].  \n",
    ": See [PreTrainedTokenizer.encode] and [PreTrainedTokenizer.__call__] for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b433b5ce-3cea-407a-94a6-b30c01b2fbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] apple people water [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence= [\"apple people water\"]\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "  \n",
    "outputs = model(**inputs)\n",
    "input_ids = inputs['input_ids'] \n",
    "# tensor([[ 101, 6207, 2111, 2300,  102]])\n",
    "\n",
    "tokenizer.decode(input_ids[0])\n",
    "# [CLS] apple people water [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7684807-59e1-415b-bf27-f7d09432880c",
   "metadata": {},
   "source": [
    "![](../images/bert_token_sequence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65987bde-9b7a-427e-baa6-7f1c55cf9a8b",
   "metadata": {},
   "source": [
    "✔ token_type_ids (= segment_ids)  \n",
    ": pre-training 단계에서 ‘NSP(Next Sentence Prediction)’ task를 위해 존재  \n",
    ": fine-tuning 시, 모두 0 (https://ratsgo.github.io/nlpbook/docs/language_model/tutorial/)  \n",
    "   \n",
    "(torch.LongTensor of shape ({0}), optional)  \n",
    ": Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]:  \n",
    "\n",
    "- corresponds to a sentence A token,\n",
    "- corresponds to a sentence B token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea584d76-4fef-4a4a-a673-dc513ed6094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_a = \"HuggingFace is based in NYC\"\n",
    "sequence_b = \"Where is HuggingFace based?\"\n",
    "\n",
    "encoded_dict = tokenizer(sequence_a, sequence_b)\n",
    "encoded_dict[\"token_type_ids\"]\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n",
    "# [CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace based? [SEP]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc780212-5a29-49e7-9c45-35aefce59e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 17662, 12172, 2003, 2241, 1999, 16392, 102, 2073, 2003, 17662, 12172, 2241, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eea65be-b19d-41da-a8e3-7a9828e06262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] huggingface is based in nyc [SEP] where is huggingface based? [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
