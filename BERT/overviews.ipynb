{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145fb0cf-106c-46ee-871a-e7ab51523ea0",
   "metadata": {},
   "source": [
    "### 참고문헌\n",
    "\n",
    "\\[1\\] [17-02 버트(Bidirectional Encoder Representations from Transformers, BERT)](https://wikidocs.net/115055)  \n",
    "\\[2\\] [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)  \n",
    "\\[3\\] [\\[BERT\\] 버트 소스코드 이해](https://hyen4110.tistory.com/87)  \n",
    "\\[4\\] [Transformers(신경망 언어모델 라이브러리) 강좌](https://wikidocs.net/book/8056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c21301-f798-4b6d-aacc-7ec5183d45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5145842-c087-48ae-a2b5-43289668312f",
   "metadata": {},
   "source": [
    "BERT는 기본적으로 훈련된 트랜스포머 인코더 스택임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd22fde-a9b1-4990-b138-56576c7defb4",
   "metadata": {},
   "source": [
    "기본적인 Bert 모델의 사용은 아래 코드와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d4126b-b4f0-4fa3-8c56-0ddc304942db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a1802e-c40b-428f-8013-d3d6ac5ee4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0060880184173583984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 64,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 48,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32ec0b17d064a37a25556dc4112c579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00410008430480957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 64,
       "postfix": null,
       "prefix": "vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215535578e9c4e96bc6e4c94c379b713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004754781723022461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 64,
       "postfix": null,
       "prefix": "tokenizer.json",
       "rate": null,
       "total": 466062,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b69fa37f89e4a3c97e7c667bb353255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004346370697021484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 64,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 570,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9845e58a338f415aa6d0d8fb48881f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004526615142822266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 64,
       "postfix": null,
       "prefix": "model.safetensors",
       "rate": null,
       "total": 440449768,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decadbfd70054fb69bab9f3537bf5942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb3af64-71c4-4117-8a92-0f3a6e2f1b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc8c94-b067-48f7-816e-4b6b4bea5bf5",
   "metadata": {},
   "source": [
    "### BertTokenizer의 output 해부\n",
    "input_ids  \n",
    ":  (torch.LongTensor of shape ({0})  \n",
    ": Indices of input sequence tokens in the vocabulary.  \n",
    ": Indices can be obtained using [BertTokenizer].  \n",
    ": See [PreTrainedTokenizer.encode] and [PreTrainedTokenizer.__call__] for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b433b5ce-3cea-407a-94a6-b30c01b2fbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] apple people water [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence= [\"apple people water\"]\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "  \n",
    "outputs = model(**inputs)\n",
    "input_ids = inputs['input_ids'] \n",
    "# tensor([[ 101, 6207, 2111, 2300,  102]])\n",
    "\n",
    "tokenizer.decode(input_ids[0])\n",
    "# [CLS] apple people water [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7684807-59e1-415b-bf27-f7d09432880c",
   "metadata": {},
   "source": [
    "![](../images/bert_token_sequence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65987bde-9b7a-427e-baa6-7f1c55cf9a8b",
   "metadata": {},
   "source": [
    "✔ token_type_ids (= segment_ids)  \n",
    ": pre-training 단계에서 ‘NSP(Next Sentence Prediction)’ task를 위해 존재  \n",
    ": fine-tuning 시, 모두 0 (https://ratsgo.github.io/nlpbook/docs/language_model/tutorial/)  \n",
    "   \n",
    "(torch.LongTensor of shape ({0}), optional)  \n",
    ": Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]:  \n",
    "\n",
    "- corresponds to a sentence A token,\n",
    "- corresponds to a sentence B token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea584d76-4fef-4a4a-a673-dc513ed6094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_a = \"HuggingFace is based in NYC\"\n",
    "sequence_b = \"Where is HuggingFace based?\"\n",
    "\n",
    "encoded_dict = tokenizer(sequence_a, sequence_b)\n",
    "encoded_dict[\"token_type_ids\"]\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n",
    "# [CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace based? [SEP]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc780212-5a29-49e7-9c45-35aefce59e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 17662, 12172, 2003, 2241, 1999, 16392, 102, 2073, 2003, 17662, 12172, 2241, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eea65be-b19d-41da-a8e3-7a9828e06262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] huggingface is based in nyc [SEP] where is huggingface based? [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
