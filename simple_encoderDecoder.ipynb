{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092edcf7-8b32-4ab3-87e8-51408b340dc9",
   "metadata": {},
   "source": [
    "chat-gpt에 아래처럼 물어본후 pytorch로 코드를 작성해달라고 부탁함.\n",
    "\n",
    "입력 - 영어 : I like the boy , 출력 : 한국어 : 나는 그 소년을 좋아한다 로 번역하는 encoder-decoder 모델을 설명해주라.\n",
    "\n",
    "하지만 버그가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41e949-e747-43d6-9bc5-b7d23a1cd4af",
   "metadata": {},
   "source": [
    "참고문헌  \n",
    "Encoder-Decoder Seq2Seq Models, Clearly Explained!!,   \n",
    "https://medium.com/analytics-vidhya/encoder-decoder-seq2seq-models-clearly-explained-c34186fbf49b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa192bd-3ccf-4685-a8b5-1164887485b3",
   "metadata": {},
   "source": [
    "- 다음은 PyTorch로 간단한 Encoder-Decoder 기반 번역 모델을 구현한 코드입니다.\n",
    "- 이 코드에는 LSTM을 사용하며, 작은 데이터셋에서 학습을 테스트할 수 있는 구조로 작성되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b8e6c-cee9-4176-bcc5-38b11fab1194",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f9aba9-04cf-4d41-9308-2cf6e780fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f18ca7-dd0b-4dd2-ab90-7e7b28ce0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 토큰화\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# 단어 사전 생성\n",
    "def build_vocab(sentences):\n",
    "    tokens = [word for sentence in sentences for word in tokenize(sentence)]\n",
    "    vocab = {word: idx for idx, word in enumerate(set(tokens), start=2)}\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "    return vocab\n",
    "\n",
    "# 문장을 숫자로 변환\n",
    "def encode(sentence, vocab):\n",
    "    return [vocab.get(word, vocab[\"<UNK>\"]) for word in tokenize(sentence)]\n",
    "\n",
    "# 패딩\n",
    "def pad_sequence(sequences, max_len):\n",
    "    return [seq + [0] * (max_len - len(seq)) for seq in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5bdff6-99f8-4678-8b22-9f184a164976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 샘플 데이터셋\n",
    "data = [\n",
    "    (\"I like the boy\", \"나는 그 소년을 좋아한다\"),\n",
    "    (\"I love apples\", \"나는 사과를 좋아한다\"),\n",
    "    (\"He likes her\", \"그는 그녀를 좋아한다\"),\n",
    "]\n",
    "\n",
    "# 데이터 준비\n",
    "src_sentences = [src for src, _ in data]\n",
    "tgt_sentences = [tgt for _, tgt in data]\n",
    "\n",
    "src_vocab = build_vocab(src_sentences)\n",
    "tgt_vocab = build_vocab(tgt_sentences)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_encoded = [encode(sentence, src_vocab) for sentence in src_sentences]\n",
    "tgt_encoded = [encode(sentence, tgt_vocab) for sentence in tgt_sentences]\n",
    "\n",
    "max_src_len = max(len(seq) for seq in src_encoded)\n",
    "max_tgt_len = max(len(seq) for seq in tgt_encoded)\n",
    "\n",
    "src_padded = pad_sequence(src_encoded, max_src_len)\n",
    "tgt_padded = pad_sequence(tgt_encoded, max_tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40947e92-8c73-43e9-bbac-f83a8e81dd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 2, 3, 9], [4, 5, 6, 0], [7, 10, 8, 0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f24d8b-d59e-460d-85f9-883c5aa25b42",
   "metadata": {},
   "source": [
    "## 데이터셋 및 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f4ccc2-70a8-4cbd-bada-4dd4612f3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = torch.tensor(src, dtype=torch.long)\n",
    "        self.tgt = torch.tensor(tgt, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.tgt[idx]\n",
    "\n",
    "dataset = TranslationDataset(src_padded, tgt_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d513c06c-487e-4fed-bb69-145e8c58aac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 2, 3, 9]), tensor([5, 2, 4, 7]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679ba4c-259b-4d21-ae02-6e90c5689aca",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aefa11e-4fbb-4087-95e0-c3f5dc278f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc(outputs)\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        hidden, cell = self.encoder(src)\n",
    "        outputs, _, _ = self.decoder(tgt, hidden, cell)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b3edb-bf19-418d-98f3-df76cb46709c",
   "metadata": {},
   "source": [
    "## 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159fe10b-93d2-4b79-8044-5d8ae51d156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1663\n",
      "Epoch [2/10], Loss: 2.1114\n",
      "Epoch [3/10], Loss: 2.0438\n",
      "Epoch [4/10], Loss: 2.0165\n",
      "Epoch [5/10], Loss: 1.9745\n",
      "Epoch [6/10], Loss: 1.8946\n",
      "Epoch [7/10], Loss: 1.8402\n",
      "Epoch [8/10], Loss: 1.8217\n",
      "Epoch [9/10], Loss: 1.7718\n",
      "Epoch [10/10], Loss: 1.6588\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "embedding_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_dim)\n",
    "decoder = Decoder(tgt_vocab_size, embedding_dim, hidden_dim)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # <PAD>는 무시\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for src, tgt in dataloader:\n",
    "        # 입력 및 출력\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        # 예측\n",
    "        outputs = model(src, tgt_input)\n",
    "        outputs = outputs.reshape(-1, tgt_vocab_size)\n",
    "        tgt_output = tgt_output.reshape(-1)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, tgt_output)\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aebeba-3e3a-4f0f-8d72-a6ffbdcfa967",
   "metadata": {},
   "source": [
    "## 예측 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e660a452-d0d3-4a59-af9c-5cb3becfeb87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<START>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 테스트\u001b[39;00m\n\u001b[1;32m     22\u001b[0m test_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI like the boy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_vocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(sentence, model, src_vocab, tgt_vocab, max_len)\u001b[0m\n\u001b[1;32m      4\u001b[0m src_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([src_encoded], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      6\u001b[0m hidden, cell \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(src_tensor)\n\u001b[0;32m----> 7\u001b[0m tgt_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[43mtgt_vocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<START>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      9\u001b[0m translation \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len):\n",
      "\u001b[0;31mKeyError\u001b[0m: '<START>'"
     ]
    }
   ],
   "source": [
    "def translate(sentence, model, src_vocab, tgt_vocab, max_len=10):\n",
    "    model.eval()\n",
    "    src_encoded = encode(sentence, src_vocab)\n",
    "    src_tensor = torch.tensor([src_encoded], dtype=torch.long)\n",
    "    \n",
    "    hidden, cell = model.encoder(src_tensor)\n",
    "    tgt_input = torch.tensor([[tgt_vocab[\"<START>\"]]], dtype=torch.long)\n",
    "    \n",
    "    translation = []\n",
    "    for _ in range(max_len):\n",
    "        output, hidden, cell = model.decoder(tgt_input, hidden, cell)\n",
    "        pred = output.argmax(2)[:, -1].item()\n",
    "        if pred == tgt_vocab[\"<END>\"]:\n",
    "            break\n",
    "        translation.append(pred)\n",
    "        tgt_input = torch.tensor([[pred]], dtype=torch.long)\n",
    "    \n",
    "    rev_tgt_vocab = {idx: word for word, idx in tgt_vocab.items()}\n",
    "    return \" \".join(rev_tgt_vocab[idx] for idx in translation)\n",
    "\n",
    "# 테스트\n",
    "test_sentence = \"I like the boy\"\n",
    "result = translate(test_sentence, model, src_vocab, tgt_vocab)\n",
    "print(f\"Input: {test_sentence}\")\n",
    "print(f\"Translation: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d3be4-4778-4eb8-9c81-4611893e304c",
   "metadata": {},
   "source": [
    "## 요약 \n",
    "위 코드는 간단한 Encoder-Decoder 구조로 번역을 구현합니다. 더 나은 성능을 위해서는 어텐션 메커니즘, 더 큰 데이터셋, 또는 Transformer 구조를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed257558-8530-4245-9a14-3a825b6fdf84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
