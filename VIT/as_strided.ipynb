{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ec1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eeaff",
   "metadata": {},
   "source": [
    "- https://iq.opengenus.org/as-strided-op-in-pytorch/\n",
    "- https://medium.com/@heyamit10/best-way-to-cut-a-pytorch-tensor-into-overlapping-chunks-14d80a99919c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683137b0",
   "metadata": {},
   "source": [
    "## What does as_strided do?  \n",
    "as_strided는 원하는 모양의 텐서를 뽑아낼 때 사용됩니다.<br>\n",
    "그 문법은 다음과 같습니다: <br>\n",
    "\n",
    "``` python\n",
    "as_strided(input, size, stride, storage_offset)\n",
    "```\n",
    "Where: <br>\n",
    "- input = Is an input tensor\n",
    "- size = The shape of the output tensor you wish to make (Specified by Tuple of Ints / Int)\n",
    "- stride = The types of steps you make while creating your output tensor (Specified by Tuple of Ints / Int)\n",
    "- storage_offset = Start position- Number of tensors as an offset you want to use before starting the creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70335ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## Basic Example  \n",
    "Say I have 3x3 matrix A  \n",
    "\n",
    "$ A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix} $\n",
    "\n",
    "I wish to create a 2 $\\times$ 2 matrix B which is a subset of A  \n",
    "\n",
    "$ B = \\begin{bmatrix} 1 & 2 \\\\ 4 & 5\\end{bmatrix} $  \n",
    "\n",
    "To do this, we see that all we need to do is to move between rows of our matrix I.e.\n",
    "\n",
    "- Go to element 1, go to the next row to retrieve 4\n",
    "- Go to element 2, go to the next row to retrieve 5\n",
    "\n",
    "as_strided는 행렬을 긴 리스트로 해석하기 때문에, 기본적으로는 A를 다음과 같은 표현으로 바라보는 것과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As strided looks at these matrices as:\n",
    "A = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32048aeb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "즉, 행(row) 사이를 이동하려면 stride를 행렬의 한 행의 길이와 같게 설정해야 한다는 뜻입니다. 이 경우에는 3이 됩니다. <br>\n",
    "이를 as_strided로 구현하면 다음과 같습니다: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96856ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "B = torch.as_strided(A, (2,2), (1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f899800",
   "metadata": {},
   "source": [
    "## Breaking Down the stride tuple:  \n",
    "이 함수 호출에서 stride 튜플이 어떻게 동작하는지 궁금할 수 있는데, 여기 그 해설이   \n",
    "있습니다.  \n",
    "\n",
    "- stride 연산은 원소를 가져오는 과정으로 생각할 수 있습니다. 즉, 하나의 창(window)이 계속해서 움직이며 슬라이딩하는 방식입니다. 이전 예제에서 그 창은 단일 원소-즉, 원소 1을 가리키고 있었습니다.  \n",
    "- stride 튜플의 첫 번째 원소는 그 창이 얼마나 움직여야 하는지를 지정합니다. 이 경우, 우리는 수평으로 한 칸씩 움직이고 싶습니다. **이를 저는 `i`라고 부르겠습니다.**\n",
    "- stride 튜플의 두 번째 원소는 원소를 가져오기 전에 몇 단계 건너뛸지를 지정합니다. 예를 들어, 우리가 현재 원소 `1`에 있을 때, 이제 `i+3`번째 인덱스를 가져오고 싶은 것입니다. <br>\n",
    "<br>\n",
    "이후에는 이보다 더 복잡한 예제를 보게 되겠지만, 이제 기본 개념을 이해했으니 좀 더 실용적인 예제로 들어갈 수 있습니다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b882738",
   "metadata": {},
   "source": [
    "## A more practical example of as_strided:\n",
    "Say for example, we wish to perform a matrix trace on a 3x3 matrix I.e.  \n",
    "<br>\n",
    "$ X = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6\\\\ 7 & 8 & 9 \\end{bmatrix} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bb666",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Our tensor representation of this would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bca683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4,5,6], [7,8,9]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10765fd4",
   "metadata": {},
   "source": [
    "Mathematically, this can be represented as:   \n",
    "$$ \\sum_{i=1}^3 a_{ii} = a_{11}+a_{22}+a_{33} $$  \n",
    "This can be implemented using some form of for loop:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e71094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15)\n"
     ]
    }
   ],
   "source": [
    "x_size = len(X[0])\n",
    "trace = 0\t\t\n",
    "for x in range(3):\n",
    "\tidx = x * x_size + x\n",
    "\ttrace += X.flatten()[idx]\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe59cf",
   "metadata": {},
   "source": [
    "To convert this into an **as_strided form**, we can differentiate the equation for the index. I.e.  \n",
    "If our for loop equation is:  \n",
    "\n",
    "$ index = x \\times \\lvert x \\rvert + x $  \n",
    "\n",
    "Differentiating with respect to x gives us:  \n",
    "$$\\frac{\\partial index}{\\partial x}=\\lvert x \\rvert + 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c81e86",
   "metadata": {},
   "source": [
    "We can then sub this in for our as_strided implementation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7903f85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15)\n"
     ]
    }
   ],
   "source": [
    "n = X.clone()\n",
    "x_size = len(X[0])\n",
    "trace = torch.as_strided(n, (x_size,), (x_size + 1,)).sum()\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a93eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d7def0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "setStorage: sizes [8, 3], strides [2, 1], storage offset 0, and itemsize 8 requiring a storage size of 136 are out of bounds for storage of size 80",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m stride \u001b[38;5;241m=\u001b[39m chunk_size \u001b[38;5;241m-\u001b[39m overlap\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Use as_strided to create overlapping chunks\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_strided\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tensor)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverlapping Chunks:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, chunks)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: setStorage: sizes [8, 3], strides [2, 1], storage offset 0, and itemsize 8 requiring a storage size of 136 are out of bounds for storage of size 80"
     ]
    }
   ],
   "source": [
    "# Example 1D tensor\n",
    "tensor = torch.arange(10)\n",
    "chunk_size = 3\n",
    "overlap = 1\n",
    "\n",
    "# Calculate stride based on the overlap\n",
    "stride = chunk_size - overlap\n",
    "\n",
    "# Use as_strided to create overlapping chunks\n",
    "chunks = tensor.as_strided(size=(tensor.size(0) - chunk_size + 1, chunk_size),\n",
    "                           stride=(stride, 1))\n",
    "\n",
    "print(\"Original Tensor:\", tensor)\n",
    "print(\"Overlapping Chunks:\\n\", chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35471ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Overlapping Chunks:\n",
      " tensor([[0, 1, 2],\n",
      "        [2, 3, 4],\n",
      "        [4, 5, 6],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10)\n",
    "chunk_size = 3\n",
    "overlap = 1\n",
    "\n",
    "# 이동 간격(step) = chunk_size - overlap\n",
    "step = chunk_size - overlap\n",
    "if step <= 0:\n",
    "    raise ValueError(\"overlap must be < chunk_size and non-negative\")\n",
    "\n",
    "N = tensor.numel()\n",
    "if N < chunk_size:\n",
    "    raise ValueError(\"tensor length must be >= chunk_size\")\n",
    "\n",
    "# 청크 개수 계산 (범위 초과 방지)\n",
    "num_chunks = 1 + (N - chunk_size) // step\n",
    "\n",
    "# as_strided로 겹치는 청크 만들기\n",
    "# 바깥(청크) 차원의 stride는 'step', 안쪽(청크 내부)은 1\n",
    "chunks = tensor.as_strided(size=(num_chunks, chunk_size),\n",
    "                           stride=(step, 1))\n",
    "\n",
    "print(\"Original Tensor:\", tensor)\n",
    "print(\"Overlapping Chunks:\\n\", chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a074137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76b68997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "576f8777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ebfee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [4, 5]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "patches = X.as_strided(size=(2, 2, 2), stride=(1, 3, 1))\n",
    "print(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bef308e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2],\n",
      "          [4, 5]],\n",
      "\n",
      "         [[2, 3],\n",
      "          [5, 6]]],\n",
      "\n",
      "\n",
      "        [[[3, 4],\n",
      "          [6, 7]],\n",
      "\n",
      "         [[4, 5],\n",
      "          [7, 8]]]])\n"
     ]
    }
   ],
   "source": [
    "patches = X.as_strided(size=(2,2, 2, 2), stride=(2, 1, 3, 1))\n",
    "print(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe99e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1, 17).view(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "931cc877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fe8f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 행렬:\n",
      " tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10],\n",
      "        [11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20],\n",
      "        [21, 22, 23, 24, 25]])\n"
     ]
    }
   ],
   "source": [
    "# 원본 5x5 행렬\n",
    "x = torch.arange(1, 26).view(5, 5)\n",
    "print(\"원본 행렬:\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d31df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[[1,2],[6,7],[[2,3],[7,8]],[[3,4],[8,9],[[4,5],[9,10]]]],\n",
    " []   \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
