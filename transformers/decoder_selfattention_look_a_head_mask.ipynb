{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457daa8a-6cf6-43ea-86d7-23e1b498b4d4",
   "metadata": {},
   "source": [
    "## 디코더의 첫번째 서브층 : 셀프 어텐션과 룩-어헤드 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fca1e9-507b-4713-b3c6-127eb539013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math, copy, time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9f82c-c291-4642-a8ca-2bcd5e801afc",
   "metadata": {},
   "source": [
    "참고문헌  \n",
    "\\[1\\] [16-01 트랜스포머(Transformer)](https://wikidocs.net/31379)  \n",
    "\\[2\\] [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html#prelims)  \n",
    "\\[3]] [Understanding Masking in PyTorch for Attention Mechanisms](https://medium.com/@swarms/understanding-masking-in-pytorch-for-attention-mechanisms-e725059fd49f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85438bc3-acad-48b2-89fd-b8ee5c2d2fbe",
   "metadata": {},
   "source": [
    "![fig1](../images/decoder._look_a_head.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf2f4e-7386-44e7-933e-3ff99c7da5e4",
   "metadata": {},
   "source": [
    "위 그림과 같이 디코더도 인코더와 동일하게 임베딩 층과 포지셔널 인코딩을 거친 후의 문장 행렬이 입력됨.  \n",
    "트랜스포머 또한 seq2seq와 마찬가지로 교사 강요(Teacher Forching)을 사용하여 훈련되므로 학습 과정에서  \n",
    "디코더는 번역할 문장에 해당되는 **\\<sos\\> je suis étudiant** 의 문장 행렬을 한 번에 입력받습니다.  \n",
    "그리고 디코더는 이 문장 행렬로부터 각 시점의 단어를 예측하도록 훈됩니다.   \n",
    "\n",
    "여기서 문제가 있습니다. seq2seq의 디코더에 사용되는 RNN 계열의 신경망은 입력 단어를 매 시점마다   \n",
    "순차적으로 입력받으므로 다음 단어 예측에 현재 시점을 포함한 이전 시점에 입력된 단어들만 참고할 수 있습니다.  \n",
    "반면, 트랜스포머는 문장 행렬로 입력을 한 번에 받으므로 현재 시점의 단어를 예측하고자 할 때,  \n",
    "입력 문장 행렬로부터 미래 시점의 단어까지도 참고할 수 있는 현상이 발생합니다. 가령, **suis**를 예측해야 하는  \n",
    "시점이라고 해봅시다. RNN 계열의 seq2seq의 디코더라면 현재까지 디코더에 입력된 단어는 **\\<sos\\>**와 **je**뿐일 것입니다.  \n",
    "반면, 트랜스포머는 이미 문장 행렬로 **\\<sos\\> je suis étudiant**를 입력받았습니다.\n",
    "\n",
    "이를 위해 트랜스포머의 디코더에서는 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어들을 참고하지  \n",
    "못하도록 **룩-어헤드 마스크 \\(look-ahead mask\\)** 를 도입했습니다. 직역하면 **미리보기에 대한 마스크**입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a9f98-5e5f-4b89-825b-f29b1481b85a",
   "metadata": {},
   "source": [
    "![fig_2](../images/decoder_mask1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b964fdc-0d8d-4229-a47a-d3d8c76b7e2f",
   "metadata": {},
   "source": [
    "**룩-어헤드 마스크**(look-ahead mask)는 디코더의 첫번째 서브층에서 이루어집니다.  \n",
    "디코더의 첫번째 서브층인 멀티 헤드 셀프 어텐션 층은 인코더의 첫번째 서브층인  \n",
    "멀티 헤드 셀프 어텐션 층과 동일한 연산을 수행합니다. 오직 다른 점은 어텐션  \n",
    "스코어 행렬에서 마스킹을 적용한다는  점만 다릅니다.  \n",
    "우선 다음과 같이 셀프 어텐션을 통해 어텐션 스코어 행렬을 얻습니다.  \n",
    "![](../images/decoder_attention_score_matrix.png)  \n",
    "\n",
    "이제 자기 자신보다 미래에 있는 단어들을 참고하지 못하도록 다음과 같이 마스킹합니다.  \n",
    "\n",
    "![](../images/look_ahead_mask.png)\n",
    "\n",
    "마스킹 된 후의 어텐션 스코어 행렬의 각 행을 보면 자기 자신과 그 이전 단어들만을 참고할  \n",
    "수 있음을 볼 수 있음. 그 외에는 근본적으로 셀프 어텐션이라는 점과 멀티 헤드 어텐션을  \n",
    "수행한다는 점에서 인코더의 첫번째 서브층과 같음.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6da2b-61d0-4203-902a-7d2ff9347679",
   "metadata": {},
   "source": [
    "### Look-ahead Mask\n",
    "Look-ahead masks prevent the model from looking at future tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c8ee-1294-4e3e-9fb6-9b26d5efc621",
   "metadata": {},
   "source": [
    "**torch.triu**는 PyTorch에서 행렬의 상삼각 행렬(upper triangular matrix) 을 추출하거나 생성하는 데  \n",
    "사용되는 함수입니다. 이 함수는 행렬의 대각선과 그 위쪽 요소를 유지하고, 나머지 요소를 0으로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742b6088-346f-4975-bef7-4627467ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59be8c3-fb32-4f00-8a90-e7977571b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "look_ahead_mask = create_look_ahead_mask(4)\n",
    "print(look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08d8c6e-bb6b-4907-a816-ac25c0c8a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores += (mask*-1e9)\n",
    "        print(scores)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a2ff7-60b4-400c-92a3-9ada481af604",
   "metadata": {},
   "source": [
    "\n",
    "``` python\n",
    "scores += (mask*-1e9)\n",
    "```\n",
    "\n",
    "- scores: shape (batch_size, num_heads, seq_len, seq_len)의 어텐션 score 행렬입니다.\n",
    "- mask: 일반적으로 0과 1 (또는 0과 -inf로 변환 가능한 값)을 가지는 tensor로, 어떤 위치의 어텐션을 막을지 지정합니다.\n",
    "  - mask가 1이면 가려야 할 위치\n",
    "  - mask가 0이면 허용되는 위치  \n",
    "-1e9: 매우 큰 음수. softmax 전에 더해지면 softmax 결과가 0에 수렴하게 만듭니다.\n",
    "\n",
    "예)\n",
    "\n",
    "``` python\n",
    "scores = [[2.0, 1.0, 3.0]]\n",
    "mask   = [[0,   1,   0]]\n",
    "```\n",
    "\n",
    "mask * -1e9 = [[0, -1e9, 0]]  \n",
    "→ scores += mask * -1e9  \n",
    "→ [[2.0, -1e9, 3.0]]  \n",
    "→ softmax 결과는 [0.119, ~0, 0.880]처럼 2번째 값이 거의 0이 됩니다.  \n",
    "즉, **softmax를 통해 해당 위치로의 attention이 사실상 불가능하도록** 만듭니다.  \n",
    "\n",
    "**왜 +=를 쓰는가?**\n",
    "\n",
    "기존의 score값에 패널티를 부여하는 방식이기 때문임.  \n",
    "- 더하기(+=)를 통해 기존 score에서 특정 위치를 제외하고 나머지는 그대로 유지됨.\n",
    "- 이 방식은 **broadcasting**으로 쉽게 적용되며 계산이 효율적임.\n",
    "\n",
    "\n",
    "**왜 마스크된 위치만 영향을 받는가?**\n",
    "- mask와 scores는 동일 shape이므로 같은 위치끼리 더해진다.\n",
    "- mask가 0인 위치는 0 * -1e9 = 0 → 영향 없음.\n",
    "- mask가 1인 위치는 1 * -1e9 = -1e9 → 해당 위치의 score에 매우 큰 패널티가 생김.\n",
    "- 따라서, +=는 **\"mask가 설정된 위치에만 -1e9를 더하는 것\"** 이 됩니다.  \n",
    "  \n",
    "**+=는 element-wise 연산임**  \n",
    "\n",
    "그리고 $-1e9 (-10^9)$는 매무큰 음수임\n",
    "\n",
    "---\n",
    "\n",
    "| 위치 | scores 값 | mask × -1e9 | 결과                       |\n",
    "|:------|:-----------|:-------------|:----------------------------|\n",
    "| 0    | 2.0       | 0           | 2.0                        |\n",
    "| 1    | 1.0       | -1e9        | 1.0 - 1e9 → 매우 작은 값   |\n",
    "| 2    | 3.0       | 0           | 3.0                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5616feaf-4eb5-4642-937a-cc3ec7f5a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.4595e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 5.8698e+00,  5.8352e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [ 5.4011e+00,  5.4265e+00,  5.6409e+00, -1.0000e+09],\n",
      "         [ 5.4078e+00,  5.6980e+00,  5.9136e+00,  5.5877e+00]],\n",
      "\n",
      "        [[ 5.8050e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 5.5221e+00,  5.8155e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [ 5.6259e+00,  5.9072e+00,  5.7836e+00, -1.0000e+09],\n",
      "         [ 5.8311e+00,  6.0171e+00,  5.9810e+00,  5.7728e+00]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5087, 0.4913, 0.0000, 0.0000],\n",
      "         [0.3033, 0.3111, 0.3855, 0.0000],\n",
      "         [0.1926, 0.2574, 0.3194, 0.2306]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4272, 0.5728, 0.0000, 0.0000],\n",
      "         [0.2861, 0.3790, 0.3349, 0.0000],\n",
      "         [0.2320, 0.2795, 0.2696, 0.2189]]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "d_model = 512\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "\n",
    "q = torch.rand((batch_size, seq_len, d_model))\n",
    "k = torch.rand((batch_size, seq_len, d_model))\n",
    "v = torch.rand((batch_size, seq_len, d_model))\n",
    "mask = create_look_ahead_mask(seq_len)\n",
    "\n",
    "attention_output, attention_weights = attention(q, k, v, mask)\n",
    "print(attention_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
