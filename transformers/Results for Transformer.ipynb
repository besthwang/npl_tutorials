{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4364a70-7bac-411e-84de-4167b486693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\anaconda3\\envs\\torchcuda113\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformer_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2dcf2f-f2c5-4b1a-bf32-79443147c704",
   "metadata": {},
   "source": [
    "### Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c4b4ee-d7fa-48a1-9eae-b0a63f613782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea811e8-1ee9-4c7d-ae15-5952fa3766ae",
   "metadata": {},
   "source": [
    "### Load data and model for output checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fd4a03-8d5a-44ab-a3e2-119f04e17612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outputs(\n",
    "    valid_dataloader,\n",
    "    model,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    n_examples=15,\n",
    "    pad_idx=2,\n",
    "    eos_string=\"</s>\",\n",
    "):\n",
    "    results = [()] * n_examples\n",
    "    for idx in range(n_examples):\n",
    "        print(\"\\nExample %d ========\\n\" % idx)\n",
    "        b = next(iter(valid_dataloader))\n",
    "        rb = Batch(b[0], b[1], pad_idx)\n",
    "        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
    "\n",
    "        src_tokens = [\n",
    "            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
    "        ]\n",
    "        tgt_tokens = [\n",
    "            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            \"Source Text (Input)        : \"\n",
    "            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        print(\n",
    "            \"Target Text (Ground Truth) : \"\n",
    "            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
    "        model_txt = (\n",
    "            \" \".join(\n",
    "                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
    "            ).split(eos_string, 1)[0]\n",
    "            + eos_string\n",
    "        )\n",
    "        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n",
    "        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_model_example(n_examples=5):\n",
    "    global vocab_src, vocab_tgt, spacy_de, spacy_en\n",
    "\n",
    "    print(\"Preparing Data ...\")\n",
    "    _, valid_dataloader = create_dataloaders(\n",
    "        torch.device(\"cpu\"),\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=1,\n",
    "        is_distributed=False,\n",
    "    )\n",
    "\n",
    "    print(\"Loading Trained Model ...\")\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n",
    "    )\n",
    "\n",
    "    print(\"Checking Model Outputs:\")\n",
    "    example_data = check_outputs(\n",
    "        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n",
    "    )\n",
    "    return model, example_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b97d11-38d5-4b9f-b86b-fae994a8d828",
   "metadata": {},
   "source": [
    "### pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091ad7ec-7bc7-4435-a9c9-c82ce7f43068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\anaconda3\\envs\\torchcuda113\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n",
      "8317\n",
      "6384\n"
     ]
    }
   ],
   "source": [
    "spacy_de, spacy_en = load_tokenizers()\n",
    "vocab_src, vocab_tgt = load_vocab(spacy_de, spacy_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4463e5d9-a851-49a3-af3f-aa51dbe3e0d9",
   "metadata": {},
   "source": [
    "## Results\n",
    "epoch가 8회 수행되었을 때는 번역 품질이 좋지 못함.\n",
    "\n",
    "-----------\n",
    "\n",
    "``` text\n",
    "Example 0 ========\n",
    "\n",
    "Source Text (Input)        : <s> Mann beobachtet eine Frau , die auf dem Gehweg raucht . </s>\n",
    "Target Text (Ground Truth) : <s> Man looking at a woman that is smoking on the sidewalk . </s>\n",
    "Model Output               : <s> Man watching woman smoking on the sidewalk . </s>\n",
    "\n",
    "Example 1 ========\n",
    "\n",
    "Source Text (Input)        : <s> Ein Mann mit einer weißen Schürze und Hut verkauft Fleisch an einer belebten Straße . </s>\n",
    "Target Text (Ground Truth) : <s> A man in a white apron and hat is selling meat on a busy street . </s>\n",
    "Model Output               : <s> A man in a white apron and hat is selling meat on a busy street . </s>\n",
    "\n",
    "Example 2 ========\n",
    "\n",
    "Source Text (Input)        : <s> Drei weiße Männer in T-Shirts springen in die Luft . </s>\n",
    "Target Text (Ground Truth) : <s> Three white men in t - shirt jump into the air . </s>\n",
    "Model Output               : <s> Three white men in t - shirts jumping in the air . </s>\n",
    "\n",
    "Example 3 ========\n",
    "\n",
    "Source Text (Input)        : <s> Zwei Kinder springen auf einem abgeschirmten blau-schwarzen Trampolin , das von Bäumen umgeben ist . </s>\n",
    "Target Text (Ground Truth) : <s> Two children jumping on a screened in blue and black trampoline while outside surrounded by trees . </s>\n",
    "Model Output               : <s> Two children are jumping on a black and blue trampoline surrounded by trees . </s>\n",
    "\n",
    "Example 4 ========\n",
    "\n",
    "Source Text (Input)        : <s> Ein kleiner Junge trägt eine <unk> Flagge und geht neben einer Frau . </s>\n",
    "Target Text (Ground Truth) : <s> A young boy carries a green , white , and red flag and walks next to a woman . </s>\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5368a388-63e6-46c7-a3ea-eab8ef1f3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\anaconda3\\envs\\torchcuda113\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dev\\anaconda3\\envs\\torchcuda113\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n",
      "C:\\Users\\dev\\anaconda3\\envs\\torchcuda113\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:180: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trained Model ...\n",
      "Checking Model Outputs:\n",
      "\n",
      "Example 0 ========\n",
      "\n",
      "Source Text (Input)        : <s> Mann beobachtet eine Frau , die auf dem Gehweg raucht . </s>\n",
      "Target Text (Ground Truth) : <s> Man looking at a woman that is smoking on the sidewalk . </s>\n",
      "Model Output               : <s> Man watching woman smoking on the sidewalk . </s>\n",
      "\n",
      "Example 1 ========\n",
      "\n",
      "Source Text (Input)        : <s> Ein Mann mit einer weißen Schürze und Hut verkauft Fleisch an einer belebten Straße . </s>\n",
      "Target Text (Ground Truth) : <s> A man in a white apron and hat is selling meat on a busy street . </s>\n",
      "Model Output               : <s> A man in a white apron and hat is selling meat on a busy street . </s>\n",
      "\n",
      "Example 2 ========\n",
      "\n",
      "Source Text (Input)        : <s> Drei weiße Männer in T-Shirts springen in die Luft . </s>\n",
      "Target Text (Ground Truth) : <s> Three white men in t - shirt jump into the air . </s>\n",
      "Model Output               : <s> Three white men in t - shirts jumping in the air . </s>\n",
      "\n",
      "Example 3 ========\n",
      "\n",
      "Source Text (Input)        : <s> Zwei Kinder springen auf einem abgeschirmten blau-schwarzen Trampolin , das von Bäumen umgeben ist . </s>\n",
      "Target Text (Ground Truth) : <s> Two children jumping on a screened in blue and black trampoline while outside surrounded by trees . </s>\n",
      "Model Output               : <s> Two children are jumping on a black and blue trampoline surrounded by trees . </s>\n",
      "\n",
      "Example 4 ========\n",
      "\n",
      "Source Text (Input)        : <s> Ein kleiner Junge trägt eine <unk> Flagge und geht neben einer Frau . </s>\n",
      "Target Text (Ground Truth) : <s> A young boy carries a green , white , and red flag and walks next to a woman . </s>\n",
      "Model Output               : <s> A young boy is wearing a <unk> hat and walking next to a woman . </s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(EncoderDecoder(\n",
       "   (encoder): Encoder(\n",
       "     (layers): ModuleList(\n",
       "       (0): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): LayerNorm()\n",
       "   )\n",
       "   (decoder): Decoder(\n",
       "     (layers): ModuleList(\n",
       "       (0): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): LayerNorm()\n",
       "   )\n",
       "   (src_embed): Sequential(\n",
       "     (0): Embeddings(\n",
       "       (lut): Embedding(8317, 512)\n",
       "     )\n",
       "     (1): PositionalEncoding(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (tgt_embed): Sequential(\n",
       "     (0): Embeddings(\n",
       "       (lut): Embedding(6384, 512)\n",
       "     )\n",
       "     (1): PositionalEncoding(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (generator): Generator(\n",
       "     (proj): Linear(in_features=512, out_features=6384, bias=True)\n",
       "   )\n",
       " ),\n",
       " [(<transformer_v2.Batch at 0x23409283fa0>,\n",
       "   ['<s>',\n",
       "    'Mann',\n",
       "    'beobachtet',\n",
       "    'eine',\n",
       "    'Frau',\n",
       "    ',',\n",
       "    'die',\n",
       "    'auf',\n",
       "    'dem',\n",
       "    'Gehweg',\n",
       "    'raucht',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'Man',\n",
       "    'looking',\n",
       "    'at',\n",
       "    'a',\n",
       "    'woman',\n",
       "    'that',\n",
       "    'is',\n",
       "    'smoking',\n",
       "    'on',\n",
       "    'the',\n",
       "    'sidewalk',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([  0, 111, 177,  16, 538,   9,   8,  90,   5,   1,   5,   1,   1,   5,\n",
       "             1,   5,   1,   5,   1,   5,   1,   1,   1,   5,   1,   1,   1,   1,\n",
       "             1,   5,   1,   1,   1,   1,   5,   1,   1,   1,   1,   1,   5,   1,\n",
       "             1,   5,   1,   1,   1,   1,   1,   1,   5,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1]),\n",
       "   '<s> Man watching woman smoking on the sidewalk . </s>'),\n",
       "  (<transformer_v2.Batch at 0x23470154700>,\n",
       "   ['<s>',\n",
       "    'Ein',\n",
       "    'Mann',\n",
       "    'mit',\n",
       "    'einer',\n",
       "    'weißen',\n",
       "    'Schürze',\n",
       "    'und',\n",
       "    'Hut',\n",
       "    'verkauft',\n",
       "    'Fleisch',\n",
       "    'an',\n",
       "    'einer',\n",
       "    'belebten',\n",
       "    'Straße',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'man',\n",
       "    'in',\n",
       "    'a',\n",
       "    'white',\n",
       "    'apron',\n",
       "    'and',\n",
       "    'hat',\n",
       "    'is',\n",
       "    'selling',\n",
       "    'meat',\n",
       "    'on',\n",
       "    'a',\n",
       "    'busy',\n",
       "    'street',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([  0,   6,  12,   7,   4,  24, 482,  11,  70,  10, 400, 749,   9,   4,\n",
       "           262,  40,   5,   1,   5,   1,   5,   1,   5,   1,   1,   5,   1,   1,\n",
       "             1,   5,   1,   5,   1,   5,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             5,   1,   1,   5,   1,   1,   5,   1,   5,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   5,   1,   5,\n",
       "             1,   1]),\n",
       "   '<s> A man in a white apron and hat is selling meat on a busy street . </s>'),\n",
       "  (<transformer_v2.Batch at 0x23409283d00>,\n",
       "   ['<s>',\n",
       "    'Drei',\n",
       "    'weiße',\n",
       "    'Männer',\n",
       "    'in',\n",
       "    'T-Shirts',\n",
       "    'springen',\n",
       "    'in',\n",
       "    'die',\n",
       "    'Luft',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'Three',\n",
       "    'white',\n",
       "    'men',\n",
       "    'in',\n",
       "    't',\n",
       "    '-',\n",
       "    'shirt',\n",
       "    'jump',\n",
       "    'into',\n",
       "    'the',\n",
       "    'air',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([  0,  59,  24,  36,   7, 216,  43, 239,  94,   7,   8, 108,   5,   1,\n",
       "             5,   1,   5,   1,   5,   1,   1,   1,   5,   1,   5,   1,   1,   5,\n",
       "             1,   1,   1,   1,   1,   1,   1,   5,   1,   1,   1,   1,   1,   5,\n",
       "             1,   5,   1,   1,   5,   1,   1,   1,   5,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             5,   1]),\n",
       "   '<s> Three white men in t - shirts jumping in the air . </s>'),\n",
       "  (<transformer_v2.Batch at 0x23409283d30>,\n",
       "   ['<s>',\n",
       "    'Zwei',\n",
       "    'Kinder',\n",
       "    'springen',\n",
       "    'auf',\n",
       "    'einem',\n",
       "    'abgeschirmten',\n",
       "    'blau-schwarzen',\n",
       "    'Trampolin',\n",
       "    ',',\n",
       "    'das',\n",
       "    'von',\n",
       "    'Bäumen',\n",
       "    'umgeben',\n",
       "    'ist',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'Two',\n",
       "    'children',\n",
       "    'jumping',\n",
       "    'on',\n",
       "    'a',\n",
       "    'screened',\n",
       "    'in',\n",
       "    'blue',\n",
       "    'and',\n",
       "    'black',\n",
       "    'trampoline',\n",
       "    'while',\n",
       "    'outside',\n",
       "    'surrounded',\n",
       "    'by',\n",
       "    'trees',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([  0,  19,  73,  17,  94,   9,   4,  26,  11,  30, 905, 332,  48, 251,\n",
       "             5,   1,   5,   1,   1,   5,   1,   5,   1,   5,   1,   1,   1,   1,\n",
       "             5,   1,   1,   1,   1,   1,   1,   1,   1,   5,   1,   1,   1,   1,\n",
       "             1,   1,   5,   1,   1,   1,   1,   5,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   5]),\n",
       "   '<s> Two children are jumping on a black and blue trampoline surrounded by trees . </s>'),\n",
       "  (<transformer_v2.Batch at 0x23409283eb0>,\n",
       "   ['<s>',\n",
       "    'Ein',\n",
       "    'kleiner',\n",
       "    'Junge',\n",
       "    'trägt',\n",
       "    'eine',\n",
       "    '<unk>',\n",
       "    'Flagge',\n",
       "    'und',\n",
       "    'geht',\n",
       "    'neben',\n",
       "    'einer',\n",
       "    'Frau',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'young',\n",
       "    'boy',\n",
       "    'carries',\n",
       "    'a',\n",
       "    'green',\n",
       "    ',',\n",
       "    'white',\n",
       "    ',',\n",
       "    'and',\n",
       "    'red',\n",
       "    'flag',\n",
       "    'and',\n",
       "    'walks',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'woman',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([ 0,  6, 25, 35, 10, 21,  4,  3, 70, 11, 42, 75, 18,  4, 16,  5,  1,  5,\n",
       "            1,  5,  1,  5,  1,  1,  1,  5,  1,  1,  1,  5,  1,  5,  1,  5,  1,  1,\n",
       "            1,  1,  1,  1,  1,  1,  5,  1,  5,  1,  5,  1,  1,  1,  1,  1,  1,  1,\n",
       "            1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]),\n",
       "   '<s> A young boy is wearing a <unk> hat and walking next to a woman . </s>')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcuda113",
   "language": "python",
   "name": "torchcuda113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
